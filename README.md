# Heart Failure Prediction

ğŸ“ æ—¥æœ¬èªç‰ˆã¯ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å¾ŒåŠã«ã‚ã‚Šã¾ã™ã€‚

> This repository contains the solution for the [Signate Competition #1394](https://signate.jp/competitions/1394): **ã€ç¬¬57å›_Beginneré™å®šã‚³ãƒ³ãƒšã€‘æ¡è¡€ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸå¿ƒä¸å…¨äºˆæ¸¬**.

The competition aims to build a predictive model using patient data to determine patients with heart failure (target = 1). The dataset includes clinical metrics and demographic information and is characterized by class imbalance.

---

## ğŸ“‚ Project Structure

- `main.ipynb` â€” main analysis and modeling notebook
- `final_model.pkl` â€” saved trained model for inference
- `requirements.txt` â€” list of dependencies

---

## ğŸ§  Problem Overview

Given a dataset of 1000 patients with clinical features, predict which ones will experience heart failure (binary classification). The dataset is imbalanced: only ~22% are positive cases.

---

## ğŸ§ª Dataset Overview

- **Rows:** 1000 samples (train), 1000 (test)
- **Features:** Clinical and lifestyle features such as:
  - `age`, `serum_creatinine`, `platelets`, `ejection_fraction`, etc.

![features correlation](img/matrix.png)

---

## ğŸ§¼ Data Preprocessing

- All numerical features were scaled using `StandardScaler`
- Custom features were engineered via a `CustomFeatureAdder`:
  - `creatinine_to_platelets` â€” ratio feature
  - `binarized_time` â€” derived binary feature from `time`
- No label encoding or one-hot encoding was necessary due to selected features being all numerical after filtering

---

## ğŸ” Model Comparison and Top Model Selection

Multiple models were tested using Stratified K-Fold cross-validation. Accuracy and F1-score were used for evaluation.

**Top performing models:**
- `LightGBM (No Resampling)`
- `GradientBoosting (No Resampling)`
- `RandomForest (No Resampling)`
- `XGBoost (ROS)`

These models were selected for use in the final ensemble.

![Model Performance Comparison](img/models.png)

---

## âœ‚ï¸ Feature Selection

Feature selection was done using `SelectFromModel` with `LGBMClassifier`:

**Final selected features:**
- `age`
- `creatinine_phosphokinase`
- `platelets`
- `serum_creatinine`
- `serum_sodium`
- `time`
- `creatinine_to_platelets`

![feature importances](img/features.png)

---

## âš™ï¸ Final Model: StackingClassifier

A `StackingClassifier` ensemble was trained on the selected features using:

### Base Models:
- `LGBMClassifier`
- `XGBClassifier`
- `CatBoostClassifier`
- `GradientBoostingClassifier`

### Meta-Model:
- `LogisticRegression(C=10)` with `passthrough=True`
- Tuned using `GridSearchCV` on final estimator

---

## ğŸ¯ Final Performance (on holdout test set)

- **Accuracy:** 0.97
- **F1-score (target = 1):** 0.93
- **Recall (target = 1):** 0.88

![confusion matrix](img/confusion_matrix.png)

## ğŸš€ How to Use

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Run predictions:
```python
import joblib, pandas as pd

model = joblib.load('final_model.pkl')
test_df = pd.read_csv('test.csv')

fe = CustomFeatureAdder()
X_test = fe.transform(test_df)[model.feature_names_in_]
y_pred = model.predict(X_test)
```

---

## ğŸ“š Acknowledgements
- data set source: https://signate.jp/competitions/1394
- LightGBM, XGBoost, CatBoost
- Scikit-learn

---

# å¿ƒä¸å…¨äºˆæ¸¬

ğŸ“ æœ¬ãƒªãƒã‚¸ãƒˆãƒªã¯ [Signate ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ #1394](https://signate.jp/competitions/1394)ï¼š**ã€ç¬¬57å›_Beginneré™å®šã‚³ãƒ³ãƒšã€‘æ¡è¡€ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸå¿ƒä¸å…¨äºˆæ¸¬** ã«å¯¾ã™ã‚‹è§£ç­”ã§ã™ã€‚

ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ã¯ã€æ‚£è€…ã®è‡¨åºŠãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å¿ƒä¸å…¨ï¼ˆtarget = 1ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯è‡¨åºŠæŒ‡æ¨™ã‚„äººå£çµ±è¨ˆæƒ…å ±ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãŒç‰¹å¾´ã§ã™ã€‚

---

## ğŸ“‚ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

- `main.ipynb` â€” åˆ†æã¨ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’è¡Œã†ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
- `final_model.pkl` â€” æ¨è«–ç”¨ã«ä¿å­˜ã•ã‚ŒãŸå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
- `requirements.txt` â€” ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒªã‚¹ãƒˆ

---

## ğŸ§  èª²é¡Œã®æ¦‚è¦

1000äººã®æ‚£è€…ã®è‡¨åºŠç‰¹å¾´é‡ã‚’ç”¨ã„ã¦ã€å¿ƒä¸å…¨ã‚’çµŒé¨“ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆäºŒå€¤åˆ†é¡ï¼‰ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä¸å‡è¡¡ã§ã‚ã‚Šã€é™½æ€§ã‚±ãƒ¼ã‚¹ã¯ç´„22%ã§ã™ã€‚

---

## ğŸ§ª ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦

- **è¡Œæ•°:** 1000ä»¶ï¼ˆè¨“ç·´ç”¨ï¼‰ã€1000ä»¶ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
- **ç‰¹å¾´é‡:** ä»¥ä¸‹ã®ã‚ˆã†ãªè‡¨åºŠãŠã‚ˆã³ç”Ÿæ´»ç¿’æ…£ã«é–¢ã™ã‚‹ç‰¹å¾´é‡ï¼š
  - `age`, `serum_creatinine`, `platelets`, `ejection_fraction` ãªã©

![ç‰¹å¾´é‡ã®ç›¸é–¢](img/matrix.png)

---

## ğŸ§¼ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†

- æ•°å€¤ç‰¹å¾´é‡ã¯ã™ã¹ã¦ `StandardScaler` ã‚’ç”¨ã„ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¾ã—ãŸ
- `CustomFeatureAdder` ã‚’ä½¿ç”¨ã—ã¦ä»¥ä¸‹ã®ã‚«ã‚¹ã‚¿ãƒ ç‰¹å¾´é‡ã‚’ä½œæˆã—ã¾ã—ãŸï¼š
  - `creatinine_to_platelets` â€” æ¯”ç‡ç‰¹å¾´é‡
  - `binarized_time` â€” `time` ã‹ã‚‰å°å‡ºã•ã‚ŒãŸãƒã‚¤ãƒŠãƒªç‰¹å¾´é‡
- æœ€çµ‚çš„ã«é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã¯ã™ã¹ã¦æ•°å€¤å‹ã§ã‚ã‚Šã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ä¸è¦ã§ã—ãŸ

---

## ğŸ” ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã¨ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ã®é¸å®š

Stratified K-Fold ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ãŸã€‚Accuracy ã¨ F1-score ã‚’è©•ä¾¡æŒ‡æ¨™ã¨ã—ã¦ã„ã¾ã™ã€‚

**ä¸Šä½ãƒ¢ãƒ‡ãƒ«ï¼š**
- `LightGBM (No Resampling)`
- `GradientBoosting (No Resampling)`
- `RandomForest (No Resampling)`
- `XGBoost (ROS)`

ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯æœ€çµ‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ä½¿ç”¨ã•ã‚Œã¾ã—ãŸã€‚

![ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ](img/models.png)

---

## âœ‚ï¸ ç‰¹å¾´é‡é¸æŠ

`LGBMClassifier` ã‚’ç”¨ã„ãŸ `SelectFromModel` ã«ã‚ˆã£ã¦ç‰¹å¾´é‡ã®é¸æŠã‚’è¡Œã„ã¾ã—ãŸï¼š

**æœ€çµ‚çš„ã«é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ï¼š**
- `age`
- `creatinine_phosphokinase`
- `platelets`
- `serum_creatinine`
- `serum_sodium`
- `time`
- `creatinine_to_platelets`

![ç‰¹å¾´é‡ã®é‡è¦åº¦](img/features.png)

---

## âš™ï¸ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«: StackingClassifier

é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã‚’ç”¨ã„ã¦ `StackingClassifier` ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸï¼š

### ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼š
- `LGBMClassifier`
- `XGBClassifier`
- `CatBoostClassifier`
- `GradientBoostingClassifier`

### ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼š
- `LogisticRegression(C=10)`ï¼ˆ`passthrough=True`ï¼‰
- `GridSearchCV` ã«ã‚ˆã£ã¦æœ€é©åŒ–

---

## ğŸ¯ æœ€çµ‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆæ¤œè¨¼ç”¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆï¼‰

- **Accuracy:** 0.97
- **F1-scoreï¼ˆtarget = 1ï¼‰:** 0.93
- **Recallï¼ˆtarget = 1ï¼‰:** 0.88

![æ··åŒè¡Œåˆ—](img/confusion_matrix.png)

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

1. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼š
```bash
pip install -r requirements.txt
```

2. äºˆæ¸¬ã®å®Ÿè¡Œï¼š
```python
import joblib, pandas as pd

model = joblib.load('final_model.pkl')
test_df = pd.read_csv('test.csv')

fe = CustomFeatureAdder()
X_test = fe.transform(test_df)[model.feature_names_in_]
y_pred = model.predict(X_test)
```

---

## ğŸ“š è¬è¾
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæä¾›å…ƒï¼šhttps://signate.jp/competitions/1394
- LightGBM, XGBoost, CatBoost
- Scikit-learn

